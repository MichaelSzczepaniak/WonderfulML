{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wonderful World of ML - Session 2 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of my favorite and most highly recommended references for machine learning are:  \n",
    "\n",
    "- [An Introduction to Statistical Learning with Applications in R - James, Witten, Hastie, and Tibshirani](https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/docs/ISLR%20Seventh%20Printing.pdf)\n",
    "- [The Elements of Statistical Learning - Hastie, Tibshirani and Friedman](https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/docs/TheElementsOfStatisticalLearning_Hastie_Tibshirani_Friedman_print10.pdf)\n",
    "\n",
    "Pdf versions of both of these books have been uploaded to the repo and can be downloaded using the links under each title.  If you are relatively new to the area of machine learning, the first reference will be your friend.  If you are an experienced pro, have great math skills and/or need more depth on a particular topic, the second reference is an excellent reference.  I will refer to the first reference as the **ISL** and the second as the **ESL** throughout the rest of this series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) If you haven't done so by now, install jupyter notebook and configure it with an R kernel if you are an R user.  If you are Python user, your Anaconda install will have Python configured out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Python users -* If you have installed the [latest version of Anaconda](https://www.continuum.io/downloads), you should have jupyter notebook as part of this install.  If you have a distribution of Python which doesn't include jupyter, you can do a **pip** install as described [here](http://jupyter.readthedocs.io/en/latest/install.html).  \n",
    "\n",
    "*R users -*  Because jupyter runs on Python, you will also need to install a Python distribution if you don't have one installed on your system already.  I recommend installing the [latest version of Anaconda](https://www.continuum.io/downloads) if you don't have a compelling reason not to use this distribution because it comes with jupyter as mentioned earlier.\n",
    "\n",
    "After Python and jupyter, I recommend that both R and Python users configure jupyter with an R kerenel.  I followed the [instructions described in this video](https://www.youtube.com/watch?v=I9a9Jj2A95g) and used [this reference](https://irkernel.github.io/installation/) as I went through the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) What was the cost function Sondra mentioned that is used for linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: **  The residual sum of squares:\n",
    "\n",
    "$$\\sum_{i=1}^n(h_{\\theta}(x_i) - y_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Equation (3.3) of the ISL defines the **Residual Sum of Squares** which can be written more generally as:\n",
    "\n",
    "$$\n",
    "RSS = \\sum_{n=1}^N (\\mathbf{t}_n - \\mathbf{x}_n^T\\mathbf{w})^2\n",
    "    = \\sum_{n=1}^N (\\mathbf{t}_n - \\mathbf{x}_n^T\\mathbf{w})(\\mathbf{t}_n - \\mathbf{x}_n^T\\mathbf{w})^T\n",
    "$$\n",
    "\n",
    "where $\\mathbf{t}_n$ is referred to as the target vector for the the *n*th sample.  Some texts refer to the target as $y$...\n",
    "\n",
    "For simple linear regression, we only have a single target $t$ and a single predictor $x$.  If we substitute $y$ for $t$, $b$ for the intercept parameter $\\hat{\\beta_0}$ and $m$ for the slope parameter $\\hat{\\beta_1}$, the above equation simplifies to:\n",
    "\n",
    "$$\n",
    "RSS = \\sum_{n=1}^N (y_n - (mx_n + b))^2\n",
    "$$\n",
    "\n",
    "If I define the arrays $\\mathbf{x}$ and $\\mathbf{y}$ as:\n",
    "\n",
    "$$\n",
    "  \\mathbf{x} =\n",
    "  \\begin{bmatrix}\n",
    "    5 \\\\ 10 \\\\ 15 \\\\ 20\n",
    "  \\end{bmatrix}\\quad\n",
    "  \\mathbf{y} =\n",
    "  \\begin{bmatrix}\n",
    "    5.5 \\\\ 6.5 \\\\ 10.5 \\\\ 9.5\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Create 3 plots on a single chart of $RSS$ on the y axis and the slope $m$ on the x axis for three values of b: 1, 3, and 5.  The code in the next block will get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>m_slope</th><th scope=col>rss</th><th scope=col>b_inter</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.0</td><td>213</td><td>1  </td></tr>\n",
       "\t<tr><td>0.2</td><td> 87</td><td>1  </td></tr>\n",
       "\t<tr><td>0.4</td><td> 21</td><td>1  </td></tr>\n",
       "\t<tr><td>0.6</td><td> 15</td><td>1  </td></tr>\n",
       "\t<tr><td>0.8</td><td> 69</td><td>1  </td></tr>\n",
       "\t<tr><td>1.0</td><td>183</td><td>1  </td></tr>\n",
       "\t<tr><td>0.0</td><td>117</td><td>3  </td></tr>\n",
       "\t<tr><td>0.2</td><td> 31</td><td>3  </td></tr>\n",
       "\t<tr><td>0.4</td><td>  5</td><td>3  </td></tr>\n",
       "\t<tr><td>0.6</td><td> 39</td><td>3  </td></tr>\n",
       "\t<tr><td>0.8</td><td>133</td><td>3  </td></tr>\n",
       "\t<tr><td>1.0</td><td>287</td><td>3  </td></tr>\n",
       "\t<tr><td>0.0</td><td> 53</td><td>5  </td></tr>\n",
       "\t<tr><td>0.2</td><td>  7</td><td>5  </td></tr>\n",
       "\t<tr><td>0.4</td><td> 21</td><td>5  </td></tr>\n",
       "\t<tr><td>0.6</td><td> 95</td><td>5  </td></tr>\n",
       "\t<tr><td>0.8</td><td>229</td><td>5  </td></tr>\n",
       "\t<tr><td>1.0</td><td>423</td><td>5  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " m\\_slope & rss & b\\_inter\\\\\n",
       "\\hline\n",
       "\t 0.0 & 213 & 1  \\\\\n",
       "\t 0.2 &  87 & 1  \\\\\n",
       "\t 0.4 &  21 & 1  \\\\\n",
       "\t 0.6 &  15 & 1  \\\\\n",
       "\t 0.8 &  69 & 1  \\\\\n",
       "\t 1.0 & 183 & 1  \\\\\n",
       "\t 0.0 & 117 & 3  \\\\\n",
       "\t 0.2 &  31 & 3  \\\\\n",
       "\t 0.4 &   5 & 3  \\\\\n",
       "\t 0.6 &  39 & 3  \\\\\n",
       "\t 0.8 & 133 & 3  \\\\\n",
       "\t 1.0 & 287 & 3  \\\\\n",
       "\t 0.0 &  53 & 5  \\\\\n",
       "\t 0.2 &   7 & 5  \\\\\n",
       "\t 0.4 &  21 & 5  \\\\\n",
       "\t 0.6 &  95 & 5  \\\\\n",
       "\t 0.8 & 229 & 5  \\\\\n",
       "\t 1.0 & 423 & 5  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "m_slope | rss | b_inter | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0.0 | 213 | 1   | \n",
       "| 0.2 |  87 | 1   | \n",
       "| 0.4 |  21 | 1   | \n",
       "| 0.6 |  15 | 1   | \n",
       "| 0.8 |  69 | 1   | \n",
       "| 1.0 | 183 | 1   | \n",
       "| 0.0 | 117 | 3   | \n",
       "| 0.2 |  31 | 3   | \n",
       "| 0.4 |   5 | 3   | \n",
       "| 0.6 |  39 | 3   | \n",
       "| 0.8 | 133 | 3   | \n",
       "| 1.0 | 287 | 3   | \n",
       "| 0.0 |  53 | 5   | \n",
       "| 0.2 |   7 | 5   | \n",
       "| 0.4 |  21 | 5   | \n",
       "| 0.6 |  95 | 5   | \n",
       "| 0.8 | 229 | 5   | \n",
       "| 1.0 | 423 | 5   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   m_slope rss b_inter\n",
       "1  0.0     213 1      \n",
       "2  0.2      87 1      \n",
       "3  0.4      21 1      \n",
       "4  0.6      15 1      \n",
       "5  0.8      69 1      \n",
       "6  1.0     183 1      \n",
       "7  0.0     117 3      \n",
       "8  0.2      31 3      \n",
       "9  0.4       5 3      \n",
       "10 0.6      39 3      \n",
       "11 0.8     133 3      \n",
       "12 1.0     287 3      \n",
       "13 0.0      53 5      \n",
       "14 0.2       7 5      \n",
       "15 0.4      21 5      \n",
       "16 0.6      95 5      \n",
       "17 0.8     229 5      \n",
       "18 1.0     423 5      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- seq(5, 20, 5)\n",
    "y <- c(5.5, 6.5, 10.5, 9.5)\n",
    "m_vals <- seq(0, 1, 0.2)\n",
    "b_vals <- seq(1, 5, 2)\n",
    "\n",
    "linearSquareResidual <- function(targets, features, m, b) {\n",
    "    yhat <- (m * features) + b\n",
    "    sqr_res <- (targets - yhat)**2\n",
    "    return(sqr_res)\n",
    "}\n",
    "\n",
    "# Remove next line if correct values are being produced. Next line is just a check.\n",
    "#list(x, y, m_vals, b_vals, linearSquareResidual(y, x, 0.4, 3))  # squared residuals = {0.25,  0.25,  2.25,  2.25}\n",
    "\n",
    "getLinRssVals <- function(y_vec, x_vec, m_vec, b_vec) {\n",
    "    rss_vals <- c()\n",
    "    for(j in 1:length(b_vec)) {\n",
    "        rss_m <- c()\n",
    "        for(i in 1: length(m_vec)) {\n",
    "            rss_m <- c(rss_m, \n",
    "                       sum(linearSquareResidual(y_vec, x_vec, m_vec[i], b_vec[j])))\n",
    "        }\n",
    "        rss_vals <- c(rss_vals, rss_m)\n",
    "    }\n",
    "    \n",
    "    return(rss_vals)\n",
    "}\n",
    "\n",
    "df <- data.frame(m_slope=rep(m_vals, length(b_vals)),\n",
    "                 rss=getLinRssVals(y, x, m_vals, b_vals),\n",
    "                 b_inter=rep(b_vals, each=length(m_vals)))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plots you just built, what are the best values for **m** and **b** that fit this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: ** m = _______, b = _______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) You are thinking about using logistic regression to determine if your stock trading has a chance of making you some money.  You design your own signal variable x which you derive from data that is readily available and use it to back-test your model on historical data.  You simulate a trade for various values of x and assign a value of 1 if the trade made money and a 0 if it lost money.  You plot your data, fit a sigmoid function through the data, and it looks like this:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/MichaelSzczepaniak/WonderfulML/master/docs/graphics/logistic_reg_stock_example.jpg\">\n",
    "\n",
    "What is the main assumption we are making in terms of how we are modeling this data?  **HINT:** What quantity are we assuming can be modeled as a line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: **  From page 132 of the ISL, we are assuming that the probability of a winning trade can be modeled as a sigmoid function which implies that the **natural log of the odds ratio** $\\ln{\\bigg(\\frac{p(x)}{1 - p(x)}\\bigg)}$ is linear (see equation 4.4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) You were excited to learn about K-Means clustering from Sondra's presentation and decided to give it a try.  You first run an analyis in using R and get one result which looks reasonable.  You then try run the same analysis in Python and again get results which look reasonable, but these results are substantially different from the results you obtained using R.\n",
    "\n",
    "Why do think you might have gotten different results on the same dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: ** The K-means algorithm is sensitive to the starting conditions your use (see ISL pages 388 and 389)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) The day after Sondra's presentation, you are having lunch with your colleague Chris who is working on helping a client who runs a large data center detect when servers may be are risk of failing.  You are excited to learn that Chris is using anomaly detection to characterize the servers in the client's datacenter and ask her what her model looks like.\n",
    "\n",
    "Chris invites you over to her desk to show you two contour plots of probability density vs. two variables.  The two variables in the first plot she calls x1 and x2 and the plot looks like this:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/MichaelSzczepaniak/WonderfulML/master/docs/graphics/circular_contours1.jpg\">\n",
    "\n",
    "She than shows you another contour plot of probability density vs. two different variable x3 and x4 which looks like this:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/MichaelSzczepaniak/WonderfulML/master/docs/graphics/eliptical_contours1.jpg\">\n",
    "\n",
    "What do these plots suggest about the relationship between x1 and x2 vs. the relationship between x3 and x4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: ** The variables x1 and x2 are independent which means the off-diagonal terms of the corvariance matrix $\\sum_k$ in equation 4.8 in the ESL are all zero.  The variables x3 and x4 appear to have some dependence which means the off-diagonal terms of the corvariance matrix $\\sum_k$ in equation 4.8 in the ESL are non-zero.\n",
    "\n",
    "We'll see this equation again when we explore Linear and Quadratic Discriminant Analysis (LDA and QDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
