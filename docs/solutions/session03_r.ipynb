{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wonderful World of ML - Session 3 Assignment (Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the references provided in session 2, I've uploading all the video and course notes from the [**Regression Models**](https://www.coursera.org/learn/regression-models) class from the Johns Hopkins Data Science Specialization on coursera to our meetup repo [here](https://github.com/focods/WonderfulML/tree/master/docs/JHU_DSS_RegMods).  This weeks assignment is adapted from an assignment given in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't done so by now, install jupyter notebook and configure it with an R kernel if you are an R user.  If you are Python user, your Anaconda install will have Python configured out of the box.  For further details, refer to the top of the session 2 notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only one problem for this session, but it's a good one..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this assignment can be found in our meetup repo:\n",
    "\n",
    "[https://raw.githubusercontent.com/focods/WonderfulML/master/data/mtcars.csv](https://raw.githubusercontent.com/focods/WonderfulML/master/data/mtcars.csv)\n",
    "\n",
    "**Here is the scenario:**  *You work for Motor Trend,Â a magazine about the automobile industry. Looking at a data set of a collection of cars, they are interested in exploring the relationship between a set of variables and miles per gallon (MPG) (outcome). They are particularly interested in the following two questions:*\n",
    "\n",
    "1. Is an automatic or manual transmission better for MPG?  \n",
    "2. Quantify the MPG difference between automatic and manual transmissions.\n",
    "\n",
    "Here is some code to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars <- read.csv(\"https://raw.githubusercontent.com/focods/WonderfulML/master/data/mtcars.csv\")\n",
    "\n",
    "head(mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's do a little EDA..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages(suppressWarnings(library(dplyr)))\n",
    "suppressMessages(suppressWarnings(library(bindrcpp)))\n",
    "suppressMessages(suppressWarnings(library(ggplot2)))\n",
    "library(dplyr)  # make sure you've done an install.packages so you have these\n",
    "library(ggplot2)\n",
    "\n",
    "suppressMessages(suppressWarnings(library(GGally)))\n",
    "suppressMessages(suppressWarnings(library(ggplot2)))\n",
    "library(GGally) #install.packages(\"GGally\")\n",
    "\n",
    "func <- function(dat=mtcars, mapping, method=\"loess\", ...) {\n",
    "    p <- ggplot(data = dat, mapping = mapping)\n",
    "    p <- p + geom_point() + geom_smooth(method=method, ...)\n",
    "    \n",
    "    return(p)\n",
    "}\n",
    "\n",
    "g <- ggpairs(mtcars[, 2:ncol(mtcars)], lower = list(continuous = wrap(func, method=\"lm\")),\n",
    "             title = \"Pairs Plot of Variables in mtcars Dataset\")\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the overall effect of transmission on MPG with this question in mind: *Is an automatic or manual transmission better for MPG?*  \n",
    "\n",
    "Let's start by taking a look at a box plot comparing all the automatics against all the manual transmissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PlotTools.R contains multiplot function\n",
    "source('../../R/PlotTools.R')  # running notebook from docs/solutions/ dir under project\n",
    "\n",
    "## boxplot to compare automatics vs manuals\n",
    "p2 <- ggplot(mtcars, aes(factor(am), mpg))\n",
    "p2 <- p2 + ggtitle(\"MPG by Transmission Only\")\n",
    "p2 <- p2 + geom_boxplot(aes(fill = factor(am)));\n",
    "p2 <- p2 + scale_fill_discrete(name=\"Transmission\", breaks=c(0,1),\n",
    "                               labels=c(\"Automatics\", \"Manuals\"))\n",
    "p2 <- p2 + theme(legend.position=c(0.2,0.85))\n",
    "p2 <- p2 + labs(x = \"Transmission (0 = Automatic)\", y = \"MPG (Miles Per Gallon)\")\n",
    "\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot suggests that manuals get better mileage than automatics.  Let's see if a t-test confirms this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(mpg ~ factor(am), paired=FALSE, var.equal=FALSE, data=mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O.k., if we assume that other factors are **not** confounding our results, then the data suggests that manuals provide give better mileage.  So our next task is to check for factors that may be confounding the results keeping in mind that our goal is to create an *appropriate* linear model which focused on the effects of transmission (**am**), **not** to create a model that best predicts MPG from the dataset.\n",
    "\n",
    "An *appropriate* model for this goal was considered to be one that accurately quantified the effects of transmission on MPG (**mpg**) with only the required number of variables. Based on our initial assumption, the process of model selection should start by first building a simple linear model with **mpg** as the response and **am** as the regressor to use as a *base*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f01 <- lm(mpg ~ am, mtcars); summary(f01)$coef # base model assuming am significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can now build successive models in a nested fashion by adding variables to the base model, and evaluating each new addition based on three criteria.  Criterion 1: The t-test from the call to **lm** indicated that the new variable does not flip signs of prior coefficients (indicating interaction between added variable and one of the existing model variables).  Criterion 2: The ANOVA comparing the prior model in the nested chain with the model including the new variable indicated a significant improvement in predicting **mpg** from the prior model.  Criterion 3: If criteria 1 and 2 were met, the confidence intervals of the newly added coefficient for manuals and automatics were calculated and if they did not overlap, this criteria was considered met and the variable included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weight\n",
    "f02 <- lm(mpg ~ am + wt, mtcars); summary(f02)$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transmission flips sign indicating interaction. Signficance of transmission falls substantially when we add weight.  Let's add an interaction term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f03 <- lm(mpg ~ am + wt + am*wt, mtcars); summary(f03)$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First two criteria are met, so let's look at the ANOVA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova(f02, f03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Adding **am*wt** interaction term improves mpg prediction, but is it necessary in quantifying the effect of transmission?  Answer this by testing whether the slopes of $\\partial{(mpg)} / \\partial{(wt)}$ are significantly different for manuals vs. automatics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.manual <- filter(mtcars, am==\"1\")\n",
    "df.autom <- filter(mtcars, am==\"0\")\n",
    "fit.manual <- lm(mpg ~ wt, data=df.manual)\n",
    "fit.autom <- lm(mpg ~ wt, data=df.autom)\n",
    "beta1.hat.manual <- summary(fit.manual)$coef[2, 1]  # -9.084268\n",
    "beta1.hat.autom <- summary(fit.autom)$coef[2, 1]    # -3.785908\n",
    "sigma.manual <- summary(fit.manual)$sigma\n",
    "sigma.autom <- summary(fit.autom)$sigma\n",
    "sigma.beta1.manual <- sigma.manual / sqrt(sum((df.manual$wt - mean(df.manual$wt))^2))\n",
    "sigma.beta1.autom <- sigma.autom / sqrt(sum((df.autom$wt - mean(df.autom$wt))^2))\n",
    "# confidence interval specifics:\n",
    "t.crit.manual <- qt(0.975, length(df.manual$am) - 2)  # 2.200985\n",
    "t.crit.autom <- qt(0.975, length(df.autom$am) - 2)  # 2.109816\n",
    "beta1.int.manual <- beta1.hat.manual + c(-1,1) * t.crit.manual * sigma.beta1.manual\n",
    "beta1.int.autom <- beta1.hat.autom + c(-1,1) * t.crit.autom * sigma.beta1.autom\n",
    "# beta1.int.manual: [-11.8500, -6.3186], beta1.int.autom: [-5.4032, -2.1686]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c(beta1.int.manual, beta1.int.autom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the 95% confidence interval of the slope of **mpg** wrt. **wt** for manual transmissions is [-11.8500, -6.3186] and for automatics is [-5.4032, -2.1686].  Since these don't overlap, these are significant and criteria 3 is met.\n",
    "\n",
    "Since looking for overlapping confidence intervals is equivalent to doing a t-test on the difference in the two slopes, as a check, let's make sure we get the same result as we just got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test specifics:\n",
    "n.manual <- length(df.manual$am)\n",
    "n.autom <- length(df.autom$am)\n",
    "dof <- n.manual + n.autom - 2\n",
    "s.pooled <- sqrt((((n.manual-1)*sigma.beta1.manual^2) +\n",
    "                      ((n.autom-1)*sigma.beta1.autom^2)) / dof) # 0.99205\n",
    "t.stat <- (beta1.hat.manual - beta1.hat.autom) *\n",
    "          (1/n.manual + 1/n.autom)^0.5 / s.pooled  # \n",
    "p_val <- pt(t.stat, dof, lower.tail=TRUE) # 0.0321 consistent w/conf int's: SIG\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Doing it this way is giving us the same results, so this is good news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\Yv}{\\mathbf{Y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\betav}{\\mathbf{\\beta}}\n",
    "\\newcommand{\\gv}{\\mathbf{g}}\n",
    "\\newcommand{\\Hv}{\\mathbf{H}}\n",
    "\\newcommand{\\dv}{\\mathbf{d}}\n",
    "\\newcommand{\\Vv}{\\mathbf{V}}\n",
    "\\newcommand{\\vv}{\\mathbf{v}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\Sv}{\\mathbf{S}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\Zv}{\\mathbf{Z}}\n",
    "\\newcommand{\\Norm}{\\mathcal{N}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}\n",
    "\\newcommand{\\dimensionbar}[1]{\\underset{#1}{\\operatorname{|}}}\n",
    "\\newcommand{\\dimensionbar}[1]{\\underset{#1}{\\operatorname{|}}}\n",
    "\\newcommand{\\grad}{\\mathbf{\\nabla}}\n",
    "\\newcommand{\\ebx}[1]{e^{\\wv_{#1}^T \\xv_n}}\n",
    "\\newcommand{\\eby}[1]{e^{y_{n,#1}}}\n",
    "\\newcommand{\\Tiv}{\\mathbf{Ti}}\n",
    "\\newcommand{\\Fv}{\\mathbf{F}}\n",
    "\\newcommand{\\ones}[1]{\\mathbf{1}_{#1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wonderful World of ML - Session 3 Discussion: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression provides a straightforward way to model the probability that one of two mutually exclusive outcomes will occur. This is another way of saying that this is a technique used for **binary classification**. Because this is one of the simplest and most popular classifiers out there, this should be in every machine learning practicioners toolbox.  It also serves as a good starting point for more sophisticated classification techniques such as LDA and QDA which we'll cover in the next session.\n",
    "\n",
    "What are some examples of binary classification?\n",
    "+ Will a team win or loss a game?\n",
    "+ Will a customer buy or not buy?\n",
    "+ Will a person survive 90 days after a myocardial infarction (heart attack)?\n",
    "+ Will a passenger survive the Titanic disaster? (kaggle competition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is logistic regression modeling?\n",
    "\n",
    "At first look, it may seem odd to call this classifier logistic *regression* until you realize that this technique is modeling the underlying conditional probability of an event occuring given one or more predictors.  In other words, we are fitting a function to $p(C=k\\,|\\, \\xv_n)$ where $C=\\text{class of }\n",
    "n^\\text{th}\\text{ sample}$ which is binary meaning that k can only be 0 or 1.  The term $\\xv_n$ is a vector of predictors for the $n^{th}$ sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is this model constructed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural way to think about modeling a probablity is to divide the count of an event by the total number of events.  Let's start by proposing a function $f(\\xv;\\wv_k)$ that is proportional to the count or frequency of a given event.  With our $f(\\xv;\\wv_k)$ as a function of our predictors $\\xv$ and some weight parameters $\\wv_k$ for each class, we can use this to compute probabilities by dividing $f(\\xv;\\wv_k)$ for a particular class $k$ by the total count in all classes which can be expressed as:\n",
    "\n",
    "1.$$\n",
    "    \\begin{align*}\n",
    "      p(C=k|\\xv) = \\frac{f(\\xv;\\wv_k)}{\\sum_{m=1}^K f(\\xv;\\wv_m)} = g_k(\\xv)\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "The above ensures that $p(C=k|\\xv)$ will be between 0 and 1 if $f(\\xv;\\wv_k) \\gt 0$, but we have another contraint which is:\n",
    "\n",
    "2.$$\n",
    "      \\begin{align*}\n",
    "      1  = \\sum_{k=1}^K p_k(C=k|\\xv) = \\sum_{k=1}^K g_k(\\xv)\n",
    "      \\end{align*}\n",
    "$$\n",
    "\n",
    "If we look closely at this equation 2., we notice that this really gives us only $(k-1)$ contraints on $g_k(\\xv)$ because we can always determine one these contraints by subtracting 1 from the sum of the other.  In other words, for some arbitrary $g_m(\\xv)$ where $m \\ne k$, we can write:\n",
    "\n",
    "3.$$\n",
    "      \\begin{align*}\n",
    "      g_m(\\xv) = 1 - \\sum_{k=1, k \\ne m}^K g_k(\\xv)\n",
    "      \\end{align*}\n",
    "$$\n",
    "\n",
    "So, we'll just set the final $f(\\xv;\\wv_k)$, for $k=K$, to be 1.  This gives us:\n",
    "\n",
    "4.$$\n",
    "      \\begin{align*}\n",
    "        g_k(\\xv) = \\left \\{ \\begin{array}{ll}\n",
    "            \\dfrac{f(\\xv;\\wv_k)}{1+\\sum_{m=1}^{K-1} f(\\xv;\\wv_m)}, & k < K\\\\\n",
    "            \\dfrac{1}{1+\\sum_{m=1}^{K-1} f(\\xv;\\wv_m)}, & k = K\n",
    "          \\end{array}\n",
    "        \\right .\n",
    "      \\end{align*}\n",
    "$$\n",
    "\n",
    "Since we are only considering two classes, we can drop the subscript $k$ and write:\n",
    "\n",
    "5.$$\n",
    "      \\begin{align*}\n",
    "        g(\\xv) = \\dfrac{f(\\xv;\\wv)}{1+f(\\xv;\\wv)}\n",
    "      \\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we select $f(\\xv;\\wv)$?  As it turns out, selecting $f(\\xv;\\wv) = e^{\\wv^T \\xv}$ allows us to more easily evaluate the gradient of the log-likelihood function which is used to find the best fit parameters which we'll touch on in the next section below.  For now, we'll just point out that selecting our $f(\\xv;\\wv)$ in this way results in the *logisitic function* shown in equation (4.2) in the ISL and more generally below:\n",
    "\n",
    "6.$$\n",
    "      \\begin{align*}\n",
    "        g(\\xv) = \\dfrac{e^{\\wv^T \\xv}}{1+e^{\\wv^T \\xv}} = p(C=k|\\xv)\n",
    "      \\end{align*}\n",
    "$$\n",
    "\n",
    "If you play with 6. a little, you can easily convince yourself that this is the same function as $sigmoid(x) = \\dfrac{1}{1+e^{-\\wv^T \\xv}}$.  Leaving 6. in the form of the logistic function allows us to more easily see that with a little manipulation, we can rewrite 6. as\n",
    "\n",
    "7.$$\n",
    "      \\begin{align*}\n",
    "        \\frac{p(C=k|\\xv)}{1 - p(C=k|\\xv)} = e^{\\wv^T \\xv} = \\text{odds or odds ratio}\n",
    "      \\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take the natural log of both sides of 7., we get a more general form of what is shown as equation (4.4) in the ISL.\n",
    "\n",
    "8.$$\n",
    "      \\begin{align*}\n",
    "        \\ln{\\Big(\\frac{p(C=k|\\xv)}{1 - p(C=k|\\xv)}\\Big)} = \\wv^T \\xv\n",
    "      \\end{align*}\n",
    "$$\n",
    "\n",
    "The left side of 8. is referred to as the *log-odd* or *logit* and we can see clearly that this model assumes that this quantity is linear in the predictors $\\xv$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we find the best parameters for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What tools are available in R to do logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R, the **glm** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we handle discrete and continuous variables in our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
