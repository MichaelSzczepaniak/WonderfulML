{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wonderful World of ML - Session 4 Assignment: Logistic Regression & Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 - Extend Logistic Regression Model From Session 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the solutions notebook for session 3, we ran a logistic regression on 2016 Broncos data.  We found that when we added the **Home** variable, the coefficient on this variable was not significantly different from 0, so we left it out of our model.\n",
    "\n",
    "In this problem, we're going to do a little feature engineering and add a variable called **YrdsDiff** which is computed by taking the difference of offensive yards minus defensive yards.  Try the following:\n",
    "\n",
    "1) Read in the revised dataset that includes offensive and defensive stats.  Treat all interger variables as continuous and rebuild the logistic regression model using just the Broncos scare and call this  model **logRegBroncos1**.\n",
    "\n",
    "2) Create a new column in the dataframe called **YrdsDiff** and populate that column with the difference of offensive yards minus defensive yards.  Build a new model using **DenWin** and the new **YrdsDiff** variable and call this model **logRegBroncos3**.\n",
    "\n",
    "3) Is the coefficient for the new **YrdsDiff** variable significantly different from 0 to justify adding it to our final model?  Why / Why not?\n",
    "\n",
    "4) What does the difference in the values for AIC for **logRegBroncos** and **logRegBroncos3** suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Date</th><th scope=col>Week</th><th scope=col>DenScore</th><th scope=col>OppScore</th><th scope=col>DenWin</th><th scope=col>Home</th><th scope=col>Off1stDwns</th><th scope=col>OffPassYrds</th><th scope=col>OffRushYrds</th><th scope=col>Def1stDwns</th><th scope=col>DefPassYrds</th><th scope=col>DefRushYrds</th><th scope=col>Notes</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>09/08/2016</td><td>1         </td><td>21        </td><td>20        </td><td>1         </td><td>1         </td><td>21        </td><td>159       </td><td>148       </td><td>21        </td><td>176       </td><td>157       </td><td>          </td></tr>\n",
       "\t<tr><td>09/18/2016</td><td>2         </td><td>34        </td><td>20        </td><td>1         </td><td>1         </td><td>24        </td><td>266       </td><td>134       </td><td>19        </td><td>170       </td><td> 83       </td><td>          </td></tr>\n",
       "\t<tr><td>09/25/2016</td><td>3         </td><td>29        </td><td>17        </td><td>1         </td><td>0         </td><td>21        </td><td>303       </td><td> 52       </td><td>20        </td><td>189       </td><td>143       </td><td>          </td></tr>\n",
       "\t<tr><td>10/02/2016</td><td>4         </td><td>27        </td><td> 7        </td><td>1         </td><td>0         </td><td>22        </td><td>218       </td><td> 89       </td><td>15        </td><td>143       </td><td> 72       </td><td>          </td></tr>\n",
       "\t<tr><td>10/09/2016</td><td>5         </td><td>16        </td><td>23        </td><td>0         </td><td>1         </td><td>18        </td><td>183       </td><td> 84       </td><td>19        </td><td>250       </td><td>122       </td><td>          </td></tr>\n",
       "\t<tr><td>10/13/2016</td><td>6         </td><td>13        </td><td>21        </td><td>0         </td><td>0         </td><td>16        </td><td>220       </td><td> 84       </td><td>16        </td><td>166       </td><td> 99       </td><td>          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllll}\n",
       " Date & Week & DenScore & OppScore & DenWin & Home & Off1stDwns & OffPassYrds & OffRushYrds & Def1stDwns & DefPassYrds & DefRushYrds & Notes\\\\\n",
       "\\hline\n",
       "\t 09/08/2016 & 1          & 21         & 20         & 1          & 1          & 21         & 159        & 148        & 21         & 176        & 157        &           \\\\\n",
       "\t 09/18/2016 & 2          & 34         & 20         & 1          & 1          & 24         & 266        & 134        & 19         & 170        &  83        &           \\\\\n",
       "\t 09/25/2016 & 3          & 29         & 17         & 1          & 0          & 21         & 303        &  52        & 20         & 189        & 143        &           \\\\\n",
       "\t 10/02/2016 & 4          & 27         &  7         & 1          & 0          & 22         & 218        &  89        & 15         & 143        &  72        &           \\\\\n",
       "\t 10/09/2016 & 5          & 16         & 23         & 0          & 1          & 18         & 183        &  84        & 19         & 250        & 122        &           \\\\\n",
       "\t 10/13/2016 & 6          & 13         & 21         & 0          & 0          & 16         & 220        &  84        & 16         & 166        &  99        &           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Date | Week | DenScore | OppScore | DenWin | Home | Off1stDwns | OffPassYrds | OffRushYrds | Def1stDwns | DefPassYrds | DefRushYrds | Notes | \n",
       "|---|---|---|---|---|---|\n",
       "| 09/08/2016 | 1          | 21         | 20         | 1          | 1          | 21         | 159        | 148        | 21         | 176        | 157        |            | \n",
       "| 09/18/2016 | 2          | 34         | 20         | 1          | 1          | 24         | 266        | 134        | 19         | 170        |  83        |            | \n",
       "| 09/25/2016 | 3          | 29         | 17         | 1          | 0          | 21         | 303        |  52        | 20         | 189        | 143        |            | \n",
       "| 10/02/2016 | 4          | 27         |  7         | 1          | 0          | 22         | 218        |  89        | 15         | 143        |  72        |            | \n",
       "| 10/09/2016 | 5          | 16         | 23         | 0          | 1          | 18         | 183        |  84        | 19         | 250        | 122        |            | \n",
       "| 10/13/2016 | 6          | 13         | 21         | 0          | 0          | 16         | 220        |  84        | 16         | 166        |  99        |            | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Date       Week DenScore OppScore DenWin Home Off1stDwns OffPassYrds\n",
       "1 09/08/2016 1    21       20       1      1    21         159        \n",
       "2 09/18/2016 2    34       20       1      1    24         266        \n",
       "3 09/25/2016 3    29       17       1      0    21         303        \n",
       "4 10/02/2016 4    27        7       1      0    22         218        \n",
       "5 10/09/2016 5    16       23       0      1    18         183        \n",
       "6 10/13/2016 6    13       21       0      0    16         220        \n",
       "  OffRushYrds Def1stDwns DefPassYrds DefRushYrds Notes\n",
       "1 148         21         176         157              \n",
       "2 134         19         170          83              \n",
       "3  52         20         189         143              \n",
       "4  89         15         143          72              \n",
       "5  84         19         250         122              \n",
       "6  84         16         166          99              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = broncos_data$DenWin ~ broncos_data$DenScore, family = \"binomial\")\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.1947  -0.2699   0.2206   0.4761   1.2306  \n",
       "\n",
       "Coefficients:\n",
       "                      Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept)            -7.0906     3.7653  -1.883   0.0597 .\n",
       "broncos_data$DenScore   0.3483     0.1702   2.047   0.0407 *\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 21.930  on 15  degrees of freedom\n",
       "Residual deviance: 10.965  on 14  degrees of freedom\n",
       "AIC: 14.965\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path <- \"https://raw.githubusercontent.com/MichaelSzczepaniak/WonderfulML/master/data/broncos2016.csv\"\n",
    "broncos_data <- read.csv(data_path)\n",
    "head(broncos_data)\n",
    "logRegBroncos <- glm(broncos_data$DenWin ~ broncos_data$DenScore, family=\"binomial\")\n",
    "summary(logRegBroncos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = broncos_data$DenWin ~ broncos_data$DenScore + broncos_data$YrdsDiff, \n",
       "    family = \"binomial\")\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-1.49668  -0.07598   0.07638   0.35998   1.35019  \n",
       "\n",
       "Coefficients:\n",
       "                       Estimate Std. Error z value Pr(>|z|)\n",
       "(Intercept)           -15.94706   10.46565  -1.524    0.128\n",
       "broncos_data$DenScore   0.74469    0.47232   1.577    0.115\n",
       "broncos_data$YrdsDiff  -0.01815    0.01417  -1.281    0.200\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 21.9301  on 15  degrees of freedom\n",
       "Residual deviance:  8.6284  on 13  degrees of freedom\n",
       "AIC: 14.628\n",
       "\n",
       "Number of Fisher Scoring iterations: 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(dplyr)\n",
    "\n",
    "broncos_data <- mutate(broncos_data, Delta1stDwns = Off1stDwns - Def1stDwns)\n",
    "broncos_data <- mutate(broncos_data, YrdsOffTotal = OffPassYrds + OffRushYrds)\n",
    "broncos_data <- mutate(broncos_data, YrdsDefTotal = DefPassYrds + DefRushYrds)\n",
    "broncos_data <- mutate(broncos_data, YrdsDiff = YrdsOffTotal - YrdsDefTotal)\n",
    "#broncos_data[, c('DenWin', 'YrdsDiff')]\n",
    "#broncos_data\n",
    "logRegBroncos3 <- glm(broncos_data$DenWin ~ broncos_data$DenScore + broncos_data$YrdsDiff, family=\"binomial\")\n",
    "summary(logRegBroncos3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Adding **YrdsDiff** is not significantly zero at 95% confidence, but the AIC is a little lower.  AIC is proxy for test error, so it suggests that **logRegBroncos3** might be slightly better than **logRegBroncos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 - Add an L2 Weight Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In session 3, we discussed how we could employ shrinkage methods to lower our risk of overfitting.  Specifically, we discussed the effects of applying L1 (lasso) and L2 (ridge) penalties to regression models.  What we did not discuss, was that you can apply them to classification.  The basic motivation behind applying these methods for classification are similar to those behind applying them for regression: We want to minimize overfitting.\n",
    "\n",
    "These 2 videos (in the repo) from the University of Washington's [**Machine Learning: Classification** class on coursera](https://www.coursera.org/learn/ml-classification/home/welcome) (requires an account on coursera) do a really nice job of describing why and how to apply an L2 weight penalty to a logistic regression model:\n",
    "\n",
    "+ [Penalizing large coefficients to mitigate overfitting](https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/docs/resources/010%20-%20Penalizing%20large%20coefficients%20to%20mitigate%20overfitting.mp4)\n",
    "+ [L2 Regularized Logistic Regression](https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/docs/resources/011%20-%20L2%20regularized%20logistic%20regression.mp4)\n",
    "\n",
    "Let's see how an L2 weight penalty can help us.  Try this task:\n",
    "\n",
    "1) Read in this cleaned and truncated version of the [Titanic data set](https://raw.githubusercontent.com/MichaelSzczepaniak/WonderfulML/master/data/titanic_class_sex_age.csv).  A description of the data can be found in the [Data Dictionary section of this document](https://github.com/MichaelSzczepaniak/Jamatitanic/blob/master/data/titanic%20data%20dictionary.pdf).  After the read, split the data into 3 partitions: 400 training sample, 200 test sample, and 114 validation samples.  Use the code provided below to get started.\n",
    "\n",
    "2) Using just the training set, fit a logistic regression model starting with **Pclass** then adding **Age** and **Sex** if they are significantly non-zero and improve AIC.  What does an improvement in AIC look like (increase or decrease)? Why?\n",
    "\n",
    "3) Use the training and validation set to determine which of these 10 values of L2 weight penalty $\\lambda$ minimizes the negative log-likelihood cost function (same as maximizing the log-likelihood).  Use the following algorithm:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>PassengerId</th><th scope=col>Survived</th><th scope=col>Pclass</th><th scope=col>Name</th><th scope=col>Sex</th><th scope=col>Age</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1                                                  </td><td>0                                                  </td><td>3                                                  </td><td>Braund, Mr. Owen Harris                            </td><td>male                                               </td><td>22                                                 </td></tr>\n",
       "\t<tr><td>2                                                  </td><td>1                                                  </td><td>1                                                  </td><td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td><td>female                                             </td><td>38                                                 </td></tr>\n",
       "\t<tr><td>3                                                  </td><td>1                                                  </td><td>3                                                  </td><td>Heikkinen, Miss. Laina                             </td><td>female                                             </td><td>26                                                 </td></tr>\n",
       "\t<tr><td>4                                                  </td><td>1                                                  </td><td>1                                                  </td><td>Futrelle, Mrs. Jacques Heath (Lily May Peel)       </td><td>female                                             </td><td>35                                                 </td></tr>\n",
       "\t<tr><td>5                                                  </td><td>0                                                  </td><td>3                                                  </td><td>Allen, Mr. William Henry                           </td><td>male                                               </td><td>35                                                 </td></tr>\n",
       "\t<tr><td>7                                                  </td><td>0                                                  </td><td>1                                                  </td><td>McCarthy, Mr. Timothy J                            </td><td>male                                               </td><td>54                                                 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " PassengerId & Survived & Pclass & Name & Sex & Age\\\\\n",
       "\\hline\n",
       "\t 1                                                   & 0                                                   & 3                                                   & Braund, Mr. Owen Harris                             & male                                                & 22                                                 \\\\\n",
       "\t 2                                                   & 1                                                   & 1                                                   & Cumings, Mrs. John Bradley (Florence Briggs Thayer) & female                                              & 38                                                 \\\\\n",
       "\t 3                                                   & 1                                                   & 3                                                   & Heikkinen, Miss. Laina                              & female                                              & 26                                                 \\\\\n",
       "\t 4                                                   & 1                                                   & 1                                                   & Futrelle, Mrs. Jacques Heath (Lily May Peel)        & female                                              & 35                                                 \\\\\n",
       "\t 5                                                   & 0                                                   & 3                                                   & Allen, Mr. William Henry                            & male                                                & 35                                                 \\\\\n",
       "\t 7                                                   & 0                                                   & 1                                                   & McCarthy, Mr. Timothy J                             & male                                                & 54                                                 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "PassengerId | Survived | Pclass | Name | Sex | Age | \n",
       "|---|---|---|---|---|---|\n",
       "| 1                                                   | 0                                                   | 3                                                   | Braund, Mr. Owen Harris                             | male                                                | 22                                                  | \n",
       "| 2                                                   | 1                                                   | 1                                                   | Cumings, Mrs. John Bradley (Florence Briggs Thayer) | female                                              | 38                                                  | \n",
       "| 3                                                   | 1                                                   | 3                                                   | Heikkinen, Miss. Laina                              | female                                              | 26                                                  | \n",
       "| 4                                                   | 1                                                   | 1                                                   | Futrelle, Mrs. Jacques Heath (Lily May Peel)        | female                                              | 35                                                  | \n",
       "| 5                                                   | 0                                                   | 3                                                   | Allen, Mr. William Henry                            | male                                                | 35                                                  | \n",
       "| 7                                                   | 0                                                   | 1                                                   | McCarthy, Mr. Timothy J                             | male                                                | 54                                                  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  PassengerId Survived Pclass\n",
       "1 1           0        3     \n",
       "2 2           1        1     \n",
       "3 3           1        3     \n",
       "4 4           1        1     \n",
       "5 5           0        3     \n",
       "6 7           0        1     \n",
       "  Name                                                Sex    Age\n",
       "1 Braund, Mr. Owen Harris                             male   22 \n",
       "2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38 \n",
       "3 Heikkinen, Miss. Laina                              female 26 \n",
       "4 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female 35 \n",
       "5 Allen, Mr. William Henry                            male   35 \n",
       "6 McCarthy, Mr. Timothy J                             male   54 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_all <- read.csv(\"https://raw.githubusercontent.com/MichaelSzczepaniak/WonderfulML/master/data/titanic_class_sex_age.csv\", na.strings = c(\"NA\", \"\"), stringsAsFactors = FALSE)\n",
    "data_all <- data_all[, c('PassengerId','Survived', 'Pclass', 'Name', 'Sex', 'Age')]\n",
    "head(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>400</li>\n",
       "\t<li>200</li>\n",
       "\t<li>114</li>\n",
       "\t<li>714</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 400\n",
       "\\item 200\n",
       "\\item 114\n",
       "\\item 714\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 400\n",
       "2. 200\n",
       "3. 114\n",
       "4. 714\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 400 200 114 714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(caret)\n",
    "library(e1071)\n",
    "set.seed(711)\n",
    "\n",
    "# Factorize the discrete variables\n",
    "data_all$Survived <- factor(data_all$Survived)\n",
    "data_all$Sex <- factor(data_all$Sex)\n",
    "data_all$Pclass <- factor(data_all$Pclass)\n",
    "\n",
    "# Create training, validation, and test datasets\n",
    "train_test_indices <- sample(1:nrow(data_all), 600)\n",
    "valid_data <- data_all[-train_test_indices, ]     # 714 - 600 = 114 validation samples\n",
    "train_indices <- sample(train_test_indices, 400)  # 400 train samples\n",
    "test_indices <- setdiff(train_test_indices, train_indices)\n",
    "train_data <- data_all[train_indices, ]\n",
    "test_data <- data_all[test_indices, ]             # 200 test samples\n",
    "# Check: If train, test, and validation are disjoint, id_keys should have nrow(data_all) = 714 rows\n",
    "id_keys <- union(union(train_data$PassengerId, test_data$PassengerId), valid_data$PassengerId)\n",
    "c(nrow(train_data), nrow(test_data), nrow(valid_data), length(id_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Survived ~ Pclass, family = \"binomial\", data = train_data)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.4028  -0.7059  -0.7059   0.9860   1.7389  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)   0.5158     0.1998   2.581  0.00984 ** \n",
       "Pclass2      -0.1863     0.2861  -0.651  0.51488    \n",
       "Pclass3      -1.7785     0.2641  -6.734 1.65e-11 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 543.58  on 399  degrees of freedom\n",
       "Residual deviance: 480.43  on 397  degrees of freedom\n",
       "AIC: 486.43\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_mod1 <- glm(Survived ~ Pclass, data=train_data, family=\"binomial\")\n",
    "summary(titanic_mod1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significance of the intercept and **Pclass** slope look good.  Let's add **Age** and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Survived ~ Pclass + Age, family = \"binomial\", data = train_data)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.1395  -0.8144  -0.5592   0.9203   2.4766  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  2.270464   0.419155   5.417 6.07e-08 ***\n",
       "Pclass2     -0.520854   0.308600  -1.688   0.0915 .  \n",
       "Pclass3     -2.493670   0.321131  -7.765 8.15e-15 ***\n",
       "Age         -0.044378   0.008941  -4.963 6.92e-07 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 543.58  on 399  degrees of freedom\n",
       "Residual deviance: 452.79  on 396  degrees of freedom\n",
       "AIC: 460.79\n",
       "\n",
       "Number of Fisher Scoring iterations: 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_mod2 <- glm(Survived ~ Pclass + Age, data=train_data, family=\"binomial\")\n",
    "summary(titanic_mod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All parameters appear significant and we got a small reduction in AIC, so it looks like we are going in the right direction.  Let's add our last parameter **Sex** and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Survived ~ Pclass + Age + Sex, family = \"binomial\", \n",
       "    data = train_data)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.7544  -0.6141  -0.3442   0.5282   2.5527  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  3.84730    0.54922   7.005 2.47e-12 ***\n",
       "Pclass2     -0.74882    0.37871  -1.977 0.048009 *  \n",
       "Pclass3     -2.54751    0.38901  -6.549 5.80e-11 ***\n",
       "Age         -0.03838    0.01034  -3.712 0.000206 ***\n",
       "Sexmale     -2.83001    0.29192  -9.695  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 543.58  on 399  degrees of freedom\n",
       "Residual deviance: 333.29  on 395  degrees of freedom\n",
       "AIC: 343.29\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_mod3 <- glm(Survived ~ Pclass + Age + Sex, data=train_data, family=\"binomial\")\n",
    "summary(titanic_mod3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All parameters are still significant and we got an even bigger reduction in AIC, so let's see how this model does on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.815789473684211"
      ],
      "text/latex": [
       "0.815789473684211"
      ],
      "text/markdown": [
       "0.815789473684211"
      ],
      "text/plain": [
       "[1] 0.8157895"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrain using caret interface for easier evaluation\n",
    "titanic_mod3 <- train(Survived ~ Pclass + Age + Sex, method='glm', data=train_data, family=\"binomial\")\n",
    "mod3_valid_results <- predict(titanic_mod3, newdata=valid_data)\n",
    "mod3_valid_acc <- sum(mod3_valid_results == valid_data$Survived) / nrow(valid_data)\n",
    "mod3_valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad, now lets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Wonderful World of ML - Session 4 Discussion: \n",
    "## Linear & Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
