{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\Yv}{\\mathbf{Y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\betav}{\\mathbf{\\beta}}\n",
    "\\newcommand{\\gv}{\\mathbf{g}}\n",
    "\\newcommand{\\Hv}{\\mathbf{H}}\n",
    "\\newcommand{\\dv}{\\mathbf{d}}\n",
    "\\newcommand{\\Vv}{\\mathbf{V}}\n",
    "\\newcommand{\\vv}{\\mathbf{v}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\Sv}{\\mathbf{S}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\Zv}{\\mathbf{Z}}\n",
    "\\newcommand{\\Norm}{\\mathcal{N}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}\n",
    "\\newcommand{\\dimensionbar}[1]{\\underset{#1}{\\operatorname{|}}}\n",
    "\\newcommand{\\dimensionbar}[1]{\\underset{#1}{\\operatorname{|}}}\n",
    "\\newcommand{\\grad}{\\mathbf{\\nabla}}\n",
    "\\newcommand{\\ebx}[1]{e^{\\wv_{#1}^T \\xv_n}}\n",
    "\\newcommand{\\eby}[1]{e^{y_{n,#1}}}\n",
    "\\newcommand{\\Tiv}{\\mathbf{Ti}}\n",
    "\\newcommand{\\Fv}{\\mathbf{F}}\n",
    "\\newcommand{\\ones}[1]{\\mathbf{1}_{#1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wonderful World of ML - Session 5 Discussion: Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees, which are also referred to as \"decision trees\" are the most basic of the machine leaning models.  The idea behind their construction is based on chopping up or partitioning feature space in a manner that best describes the data.  Their strength lies primarily in their interpretability, while their weekness lies in their inability to describe for complex relationships.\n",
    "\n",
    "Let's start by taking a look a couple of simple trees. The data for the tree in **Figure 1.A** was taken from the **ISLR** package in **R** and can be found [here](https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/data/HittersISLR.csv) (1.).  The data for the tree in **Figure 1.B** was originally downloaded from [here](http://www-bcf.usc.edu/~gareth/ISL/Heart.csv), but it has been replicated [here](https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/data/Heart.csv) in case the original link goes away.\n",
    "\n",
    "<img src=\"https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/docs/graphics/Trees_03_Fig1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1.A** shows an example of a **regression tree**.  **Figure 1.B** shows an example of a **classification tree**.  While both of these trees are binary (only split 2 ways at each node), they can contain more than 2 splits at any node as shown by the **Credit** node in **Figure 2.** below.\n",
    "\n",
    "<img src=\"https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/docs/graphics/Trees_04_Fig2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another difference to notice are the types of variable each node is split on.  In **Figure 1.A**, all the nodes are continuous variables.  In **Figure 2.**, all the nodes are treated as catagorical.  In **Figure 1.B**, the root (top) node is catagorical and the rest are continuous.  So trees are flexible enough to handle both catagorical and continuous variables.\n",
    "\n",
    "So once we have trained/built our tree, how do we make a prediction with new data?  This turns out to pretty easy.  All we have to do is follow the path from the root node to a leaf node.  Let's do a simple example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a prediction with a tree\n",
    "\n",
    "#### Example 1. - Regression\n",
    "\n",
    "Assume that the **leaf nodes** (terminal nodes at the bottom of the tree where values for predicitons are obtained) in **Figure 1.A** are log (base 10) values of salaries for baseball players.  What would the model predict for the salary of a player that has been in the league 7 years and had 113 hits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answer 1.\n",
    "\n",
    "Starting at the top (root) node of the tree in **Figure 1.A**, we traverse right because 7 > 4.5.  This brings us to the **Hits** node where we split left because 113 < 117.5.  This brings us to the leaf with value of **6.0**.  Since this is the base-10 log of the salary, our prediction would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted salary = $1000000.00\n"
     ]
    }
   ],
   "source": [
    "print(\"predicted salary = ${:.2f}\".format(10**(6.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to notice\n",
    "\n",
    "Notice how this regression tree will output the same value for a whole region of feature space.  For example, if we a player had been playing for 10 years and had 115 hits, the prediction would be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2. - Classification\n",
    "\n",
    "The leaf nodes in **Figure 1.B** represent the presence of heart disease.  A **Yes** means that heart disease is present and **No** means heart disease is not present.  If the **Thal** (Thallium stress test) is normal (left branch of this node), what would the model predict for an individual with [**Ca**](http://archive.ics.uci.edu/ml/datasets/heart+Disease) < 0.5 and a maximum heart rate (**MaxHR**) > 161.5?  Would the model's prediction change if **MaxHR** < 161.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answer 2. \n",
    "Following the left branch from the root (**Thal:a**) node, at the **Ca < 0.5** node, we follow the left branch to the **MaxHR** node and then to right **No** leaf node.  Because both leaf nodes under **MaxHR** are **No**, the model prediction would not change if maximum heart rate were < 161.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Trees\n",
    "\n",
    "A tree represents a recipe for how to slice up feature space.  The better the recipe, the better the predictions the tree is able to make.  So how do we build trees that make good predictions on test data?  Like other machine learning models, we typically derive some cost function to minimize or objective function to maximize and trees are no different in this regard.\n",
    "\n",
    "#### Regression Trees\n",
    "\n",
    "Like linear regression, the residual sum of squares (RSS) is well suited for training regression trees.  Also similar to linear regression models, we need to select predictors that matter and discard ones that don't.  The way this is typically done for regression trees is to grow a full tree with all the predictors and follow this by applying a technique called **cost complexity pruning** or **weakest link pruning** to remove branches that aren't as important.  See chapter 8 of the ISL for details regarding this procuedure.\n",
    "\n",
    "#### Classification Trees\n",
    "\n",
    "Training classification trees requires using one of three typical cost functions: \n",
    "\n",
    "+ Overall Error Rate\n",
    "+ Gini Score\n",
    "+ Cross-Entropy\n",
    "\n",
    "#### Overall Error Rate\n",
    "\n",
    "This is the most intuitive cost function used to building decisions trees.  To compute the overall error rate, we simpy count the number of mistakes the tree made in making predictions and then divide this by the total number of predictions.  Using the overall error rate will work as well as the other two for binary trees because they all are 0 for a pure group (either all group 1, $p_1 = 0$ or all group 2, $p_2 = 0$) and take on their maximum value when a binary group is least pure i.e. when $p_1 = p_2 = 0.5$ as shown in Figure 3. below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAHjCAYAAAADuoh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwF4dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4a52f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.72192809,  0.97095059,  0.97095059,  0.72192809,  0.        ])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Returns the binary error rate\n",
    "# prob - probability of one of binary classes\n",
    "def overallError(prob):\n",
    "    error = prob\n",
    "    if(prob > 0.5):\n",
    "        error = 1 - prob\n",
    "        \n",
    "    return error\n",
    "\n",
    "# Returns the binary cross-entropy cost\n",
    "# prob - probability of one of binary classes\n",
    "def crossEntropy(prob):\n",
    "    if prob > 0 and prob < 1:\n",
    "        return -((prob * math.log(prob, 2)) + ((1 - prob) * math.log(1 - prob, 2)))\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "# Returns the binary gini score\n",
    "# prob - probability of one of binary classes\n",
    "def giniScore(prob):\n",
    "    return prob * (1. - prob)\n",
    "\n",
    "# vectorize the cost functions\n",
    "overallError = np.vectorize(overallError)\n",
    "crossEntropy = np.vectorize(crossEntropy)\n",
    "giniScore = np.vectorize(giniScore)\n",
    "\n",
    "probs = np.linspace(0, 1.0, 101)\n",
    "# Plot 3 cost functions\n",
    "import matplotlib as mp, matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(probs, overallError(probs), 'g^', label='overall error')\n",
    "plt.plot(probs, crossEntropy(probs), 'ro', label='cross-entropy')\n",
    "plt.plot(probs, giniScore(probs), 'bs', label='gini score')\n",
    "plt.xlabel(\"p1\")\n",
    "plt.ylabel(\"cost function or impurity\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "crossEntropy(np.array([0, 0.2, 0.4, 0.6, 0.8, 1.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The problem with the overall error rate starts to show itself when we try to move beyond binary classification.  When we try to classify into 3 or more classes, we find that the overall error rate is not as sensitive as the *Gini Score* or *Cross-Entropy*.  To see a good little example of why the *Cross-Entropy* is a better cost function, check out [this little write up](http://rpubs.com/mszczepaniak/classificationgoodness).  A similar intuition can be applied in explaining why *Gini Score* is superior to overall error rate as shown [in this spreadsheet](https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/data/gini_score.xls)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Overfitting\n",
    "\n",
    "What might an overfit tree looks like?  Let's take a look at the data used to create **Figure 1.B**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>140</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>130</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  \\\n",
       "0   63    1       typical     145   233    1        2    150      0      2.3   \n",
       "1   67    1  asymptomatic     160   286    0        2    108      1      1.5   \n",
       "2   67    1  asymptomatic     120   229    0        2    129      1      2.6   \n",
       "3   37    1    nonanginal     130   250    0        0    187      0      3.5   \n",
       "4   41    0    nontypical     130   204    0        2    172      0      1.4   \n",
       "5   56    1    nontypical     120   236    0        0    178      0      0.8   \n",
       "6   62    0  asymptomatic     140   268    0        2    160      0      3.6   \n",
       "7   57    0  asymptomatic     120   354    0        0    163      1      0.6   \n",
       "8   63    1  asymptomatic     130   254    0        2    147      0      1.4   \n",
       "9   53    1  asymptomatic     140   203    1        2    155      1      3.1   \n",
       "\n",
       "   Slope   Ca        Thal  AHD  \n",
       "0      3  0.0       fixed   No  \n",
       "1      2  3.0      normal  Yes  \n",
       "2      2  2.0  reversable  Yes  \n",
       "3      3  0.0      normal   No  \n",
       "4      1  0.0      normal   No  \n",
       "5      1  0.0      normal   No  \n",
       "6      3  2.0      normal  Yes  \n",
       "7      1  0.0      normal   No  \n",
       "8      2  1.0  reversable  Yes  \n",
       "9      3  0.0  reversable  Yes  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "heart_data = pd.read_csv(\"https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/data/Heart.csv\")\n",
    "heart_data.iloc[:, 1:].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For illustration purposes, let's pretend these first 10 samples was the training data set.  How well would this tree do at predicting heart diseast (AHD)?\n",
    "\n",
    "+ If Thal=reversable, **then** AHD = Yes\n",
    "+ If Thal=fixed, **then** AHD = No\n",
    "+ If Thal=normal and Ca > 1.0, **then** AHD = Yes\n",
    "+ Else, AHD = No\n",
    "\n",
    "This simple tree would result in a 0% error rate (perfect classifier) on the training data.  How would this tree do on unseen?  Let's apply this tree to the next 10 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>120</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>110</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  \\\n",
       "10   57    1  asymptomatic     140   192    0        0    148      0      0.4   \n",
       "11   56    0    nontypical     140   294    0        2    153      0      1.3   \n",
       "12   56    1    nonanginal     130   256    1        2    142      1      0.6   \n",
       "13   44    1    nontypical     120   263    0        0    173      0      0.0   \n",
       "14   52    1    nonanginal     172   199    1        0    162      0      0.5   \n",
       "15   57    1    nonanginal     150   168    0        0    174      0      1.6   \n",
       "16   48    1    nontypical     110   229    0        0    168      0      1.0   \n",
       "17   54    1  asymptomatic     140   239    0        0    160      0      1.2   \n",
       "18   48    0    nonanginal     130   275    0        0    139      0      0.2   \n",
       "19   49    1    nontypical     130   266    0        0    171      0      0.6   \n",
       "\n",
       "    Slope   Ca        Thal  AHD predictions  \n",
       "10      2  0.0       fixed   No          No  \n",
       "11      2  0.0      normal   No          No  \n",
       "12      2  1.0       fixed  Yes          No  \n",
       "13      1  0.0  reversable   No         Yes  \n",
       "14      1  0.0  reversable   No         Yes  \n",
       "15      1  0.0      normal   No          No  \n",
       "16      3  0.0  reversable  Yes         Yes  \n",
       "17      1  0.0      normal   No          No  \n",
       "18      1  0.0      normal   No          No  \n",
       "19      1  0.0      normal   No          No  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Little function that encodes the tree in the prior cell\n",
    "def overfit(thal, ca) :\n",
    "    if (thal == \"reversable\"):\n",
    "        adh = \"Yes\"\n",
    "    elif(thal == \"fixed\"):\n",
    "        adh = \"No\"\n",
    "    elif(thal == \"normal\" and ca > 1.0):\n",
    "        adh = \"Yes\"\n",
    "    else:\n",
    "        adh = \"No\"\n",
    "    return adh\n",
    "\n",
    "overfit = np.vectorize(overfit)\n",
    "preds = overfit(heart_data.iloc[10:, 13].head(10), heart_data.iloc[10:, 12].head(10))\n",
    "h = heart_data.iloc[10:, 1:].head(10)\n",
    "# https://stackoverflow.com/questions/12555323/adding-new-column-to-existing-dataframe-in-python-pandas\n",
    "h['predictions'] = preds\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier that did perfectly on the training data would misclassify samples 12, 13, and 14.  Just like fitting a high order polynomial when doing regression, trees can be overfit as well.  How might we regularize our tree models so that they don't overfit our training data?  Good question!  This is the kind of question good machine learning practicioners ask themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### One Option: Take the Gordon Geko approach - [\"Greed, for lack of better word, is good!\"](https://en.wikipedia.org/wiki/Gordon_Gekko)\n",
    "\n",
    "The most basic algorithm for fitting a tree is the *top-down, greedy* aka the *recursive binary splitting* algorithm.  It works like this:\n",
    "\n",
    "1. Select a predictor (e.g. X1).\n",
    "2. Select a sample (e.g. row[0]).\n",
    "3. Split all the data in the training set into each of the two classes using the value of the selected predictor on the selected sample as the threshold.  Values less than the threshold, collect in a left group.  Values greater than or equal the threshold, collect into a right group.\n",
    "4. Compute the cost function for this split. We'll use the gini score.\n",
    "5. Repeat steps 2. thru 4. for each successive sample value of the predictor selected in step 1. as the threshold\n",
    "6. Repeat steps 1. thru 5. for the remaining predictors\n",
    "7. Select the root node and the threshold for all the splits done in steps 1. thru 6. based on the predictor and sample with the minimum value for gini score.\n",
    "8. Continue repeating steps 1. thru 7. on each resulting split group until some over-fitting criteria is met.\n",
    "\n",
    "\n",
    "\n",
    "p311 of ISL and\n",
    "https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/#crayon-599e33756fd9d927607695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAHjCAYAAAADuoh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# test data from http://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
    "dataset = np.array([[2.771244718,1.784783929,0],\n",
    "                    [1.728571309,1.169761413,0],\n",
    "                    [3.678319846,2.81281357,0],\n",
    "                    [3.961043357,2.61995032,0],\n",
    "                    [2.999208922,2.209014212,0],\n",
    "                    [7.497545867,3.162953546,1],\n",
    "                    [9.00220326,3.339047188,1],\n",
    "                    [7.444542326,0.476683375,1],\n",
    "                    [10.12493903,3.234550982,1],\n",
    "                    [6.642287351,3.319983761,1]])\n",
    "\n",
    "# Visualize the test data\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(dataset[:5,0], dataset[:5,1], 'bo', label='class 0')\n",
    "plt.plot(dataset[5:,0], dataset[5:,1], 'rs', label='class 1')\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.legend(loc='center right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 < 2.771 Gini=0.444\n",
      "X1 < 1.729 Gini=0.500\n",
      "X1 < 3.678 Gini=0.286\n",
      "X1 < 3.961 Gini=0.167\n",
      "X1 < 2.999 Gini=0.375\n",
      "X1 < 7.498 Gini=0.286\n",
      "X1 < 9.002 Gini=0.375\n",
      "X1 < 7.445 Gini=0.167\n",
      "X1 < 10.125 Gini=0.444\n",
      "X1 < 6.642 Gini=0.000\n",
      "X2 < 1.785 Gini=0.500\n",
      "X2 < 1.170 Gini=0.444\n",
      "X2 < 2.813 Gini=0.320\n",
      "X2 < 2.620 Gini=0.417\n",
      "X2 < 2.209 Gini=0.476\n",
      "X2 < 3.163 Gini=0.167\n",
      "X2 < 3.339 Gini=0.444\n",
      "X2 < 0.477 Gini=0.500\n",
      "X2 < 3.235 Gini=0.286\n",
      "X2 < 3.320 Gini=0.375\n",
      "Split: [X1 < 6.642]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# https://stackoverflow.com/questions/4383571/importing-files-from-different-folder\n",
    "sys.path.insert(0, '../../Python/')\n",
    "import BinaryDecisionTree as b\n",
    "split = b.evalSplits(dataset)\n",
    "print('Split: [X%d < %.3f]' % ((split['index']+1), split['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 < 2.771 Gini=0.444\n",
      "X1 < 1.729 Gini=0.500\n",
      "X1 < 3.678 Gini=0.286\n",
      "X1 < 3.961 Gini=0.167\n",
      "X1 < 2.999 Gini=0.375\n",
      "X1 < 7.498 Gini=0.286\n",
      "X1 < 9.002 Gini=0.375\n",
      "X1 < 7.445 Gini=0.167\n",
      "X1 < 10.125 Gini=0.444\n",
      "X1 < 6.642 Gini=0.000\n",
      "X2 < 1.785 Gini=0.500\n",
      "X2 < 1.170 Gini=0.444\n",
      "X2 < 2.813 Gini=0.320\n",
      "X2 < 2.620 Gini=0.417\n",
      "X2 < 2.209 Gini=0.476\n",
      "X2 < 3.163 Gini=0.167\n",
      "X2 < 3.339 Gini=0.444\n",
      "X2 < 0.477 Gini=0.500\n",
      "X2 < 3.235 Gini=0.286\n",
      "X2 < 3.320 Gini=0.375\n",
      "[X1 < 6.642]\n",
      " [0.0]\n",
      " [1.0]\n"
     ]
    }
   ],
   "source": [
    "tree = b.buildTree(dataset, 1, 1)\n",
    "b.printTree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 < 2.771 Gini=0.444\n",
      "X1 < 1.729 Gini=0.500\n",
      "X1 < 3.678 Gini=0.286\n",
      "X1 < 3.961 Gini=0.167\n",
      "X1 < 2.999 Gini=0.375\n",
      "X1 < 7.498 Gini=0.286\n",
      "X1 < 9.002 Gini=0.375\n",
      "X1 < 7.445 Gini=0.167\n",
      "X1 < 10.125 Gini=0.444\n",
      "X1 < 6.642 Gini=0.000\n",
      "X2 < 1.785 Gini=0.500\n",
      "X2 < 1.170 Gini=0.444\n",
      "X2 < 2.813 Gini=0.320\n",
      "X2 < 2.620 Gini=0.417\n",
      "X2 < 2.209 Gini=0.476\n",
      "X2 < 3.163 Gini=0.167\n",
      "X2 < 3.339 Gini=0.444\n",
      "X2 < 0.477 Gini=0.500\n",
      "X2 < 3.235 Gini=0.286\n",
      "X2 < 3.320 Gini=0.375\n",
      "X1 < 2.771 Gini=0.000\n",
      "X1 < 1.729 Gini=0.000\n",
      "X1 < 3.678 Gini=0.000\n",
      "X1 < 3.961 Gini=0.000\n",
      "X1 < 2.999 Gini=0.000\n",
      "X2 < 1.785 Gini=0.000\n",
      "X2 < 1.170 Gini=0.000\n",
      "X2 < 2.813 Gini=0.000\n",
      "X2 < 2.620 Gini=0.000\n",
      "X2 < 2.209 Gini=0.000\n",
      "X1 < 7.498 Gini=0.000\n",
      "X1 < 9.002 Gini=0.000\n",
      "X1 < 7.445 Gini=0.000\n",
      "X1 < 10.125 Gini=0.000\n",
      "X1 < 6.642 Gini=0.000\n",
      "X2 < 3.163 Gini=0.000\n",
      "X2 < 3.339 Gini=0.000\n",
      "X2 < 0.477 Gini=0.000\n",
      "X2 < 3.235 Gini=0.000\n",
      "X2 < 3.320 Gini=0.000\n",
      "[X1 < 6.642]\n",
      " [X1 < 2.771]\n",
      "  [0.0]\n",
      "  [0.0]\n",
      " [X1 < 7.498]\n",
      "  [1.0]\n",
      "  [1.0]\n"
     ]
    }
   ],
   "source": [
    "tree2 = b.buildTree(dataset, 2, 1)\n",
    "b.printTree(tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n"
     ]
    }
   ],
   "source": [
    "#  predict with a stump\n",
    "stump = {'index': 0, 'right': 1, 'value': 6.642287351, 'left': 0}\n",
    "for row in dataset:\n",
    "    prediction = b.predict(stump, row)\n",
    "    print('Expected=%d, Got=%d' % (row[-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3]; y = [4,5,6,7]\n",
    "groups = x, y\n",
    "group_sizes = [len(group) for group in groups]\n",
    "group_sizes\n",
    "sum(group_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strength in numbers?\n",
    "\n",
    "Consider two binary classification scenarios where you've built 3 decision trees in each scenario.  Each of your 3 trees has about the same overall error rate and gini score when run on *test data*.  You think to yourself: *I could run all three models and give each model a **vote** and assign the class based on which one gets the most votes.*\n",
    "\n",
    "Would this approach lead to a better predictor overall?  Like so many things in life, the answer is: **\"it depends\"**.  Let's see if we can discover the conditions under which we may or may not improve the prediction accuracy using this voting approach.  Start by considering three scenarios:\n",
    "\n",
    "+ **Scenario A:** One model tends to make most of its errors by predicting class 0 when truth is class 1.  Another model tends to make most of its errors by predicting class 1 when truth is class 0.  The third model tends to make errors on both classes at roughly and equal rate.\n",
    "+ **Scenario B:** All three models tend to make most of their errors by predicting class 0 when truth is class 1.\n",
    "+ **Scenario C:** All three models tend to make most of their errors by predicting class 1 when truth is class 0.\n",
    "\n",
    "Would you expect any of these scenarios lead to improved prediction accuracy?  If so which one(s)?  Why?  \n",
    "\n",
    "Consider another scenarios: You have a 100 newly built digital clocks that tell you date and time.  If you averaged the date and time reported by each clock, would you expect this average to be significantly high, low or relatively close to the true date and time.  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References\n",
    "\n",
    "1. Figures 1.A and 1.B are taken from \"An Introduction to Statistical Learning, with applications in R\"  (Springer, 2013) with permission from the authors: G. James, D. Witten,  T. Hastie and R. Tibshirani"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
