{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wonderful World of ML - Session 4 Assignment: Logistic Regression & Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 - Extend Logistic Regression Model From Session 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the solutions notebook for session 3, we ran a logistic regression on 2016 Broncos data.  We found that when we added the **Home** variable, the coefficient on this variable was not significantly different from 0, so we left it out of our model.\n",
    "\n",
    "In this problem, we're going to do a little feature engineering and add a variable called **YrdsDiff** which is computed by taking the difference of offensive yards minus defensive yards.  Try the following:\n",
    "\n",
    "1) Read in the revised dataset that includes offensive and defensive stats.  Treat all interger variables as continuous and rebuild the logistic regression model using just the Broncos scare and call this  model **logRegBroncos1**.\n",
    "\n",
    "2) Create a new column in the dataframe called **YrdsDiff** and populate that column with the difference of offensive yards minus defensive yards.  Build a new model using **DenWin** and the new **YrdsDiff** variable and call this model **logRegBroncos3**.\n",
    "\n",
    "3) Is the coefficient for the new **YrdsDiff** variable significantly different from 0 to justify adding it to our final model?  Why / Why not?\n",
    "\n",
    "4) What does the difference in the values for AIC for **logRegBroncos** and **logRegBroncos3** suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Week</th>\n",
       "      <th>DenScore</th>\n",
       "      <th>OppScore</th>\n",
       "      <th>DenWin</th>\n",
       "      <th>Home</th>\n",
       "      <th>Off1stDwns</th>\n",
       "      <th>OffPassYrds</th>\n",
       "      <th>OffRushYrds</th>\n",
       "      <th>Def1stDwns</th>\n",
       "      <th>DefPassYrds</th>\n",
       "      <th>DefRushYrds</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09/08/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>159</td>\n",
       "      <td>148</td>\n",
       "      <td>21</td>\n",
       "      <td>176</td>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/18/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>266</td>\n",
       "      <td>134</td>\n",
       "      <td>19</td>\n",
       "      <td>170</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/25/2016</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>303</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>189</td>\n",
       "      <td>143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/02/2016</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>218</td>\n",
       "      <td>89</td>\n",
       "      <td>15</td>\n",
       "      <td>143</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/09/2016</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>183</td>\n",
       "      <td>84</td>\n",
       "      <td>19</td>\n",
       "      <td>250</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Week  DenScore  OppScore  DenWin  Home  Off1stDwns  \\\n",
       "0  09/08/2016     1        21        20       1     1          21   \n",
       "1  09/18/2016     2        34        20       1     1          24   \n",
       "2  09/25/2016     3        29        17       1     0          21   \n",
       "3  10/02/2016     4        27         7       1     0          22   \n",
       "4  10/09/2016     5        16        23       0     1          18   \n",
       "\n",
       "   OffPassYrds  OffRushYrds  Def1stDwns  DefPassYrds  DefRushYrds Notes  \n",
       "0          159          148          21          176          157   NaN  \n",
       "1          266          134          19          170           83   NaN  \n",
       "2          303           52          20          189          143   NaN  \n",
       "3          218           89          15          143           72   NaN  \n",
       "4          183           84          19          250          122   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "#import scikit??? as ???\n",
    "data_path = \"https://raw.githubusercontent.com/MichaelSzczepaniak/WonderfulML/master/data/broncos2016.csv\"\n",
    "broncos_data = pd.read_csv(data_path)\n",
    "broncos_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Implement building these models by hand and research how to:\n",
    "\n",
    "1. Build logsitic regression models with Python 3.x compatible package (e.g. sklearn, statsmodels, et. al.)\n",
    "2. Do F-tests between 2 nested modles.  [My post of Stackoverflow](https://stackoverflow.com/questions/45243802/how-do-i-do-an-f-test-to-compare-nested-linear-models-in-python) recommends using the  **feature_selection.f_regression** function, but need to spend some time on this because it didn't look very intuitive upon my initial read through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Problem 2 - Add an L2 Weight Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In session 3, we discussed how we could employ shrinkage methods to regression models to lower our risk of overfitting.  Specifically, we discussed the effects of applying L1 (lasso) and L2 (ridge) penalties.  What we did not discuss, was that you can apply them to classification.  The basic motivation behind applying these methods for classification are similar to those behind applying them for regression: We want to minimize overfitting.\n",
    "\n",
    "These 2 videos (in the repo) from the [**Machine Learning: Classification** class on coursera](https://www.coursera.org/learn/ml-classification/home/welcome) (requires an account on coursera) do a really nice job of describing why and how to apply an L2 weight penalty to a logistic regression model:\n",
    "\n",
    "+ [Penalizing large coefficients to mitigate overfitting](https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/docs/resources/010%20-%20Penalizing%20large%20coefficients%20to%20mitigate%20overfitting.mp4)\n",
    "+ [L2 Regularized Logistic Regression](https://github.com/MichaelSzczepaniak/WonderfulML/raw/master/docs/resources/011%20-%20L2%20regularized%20logistic%20regression.mp4)\n",
    "\n",
    "Let's see how an L2 weight penalty can help us.  Try this task:\n",
    "\n",
    "1) Read in this cleaned and truncated version of the [Titanic data set](https://raw.githubusercontent.com/MichaelSzczepaniak/WonderfulML/master/data/titanic_class_sex_age.csv) and split the data into 3 partitions: 400 training sample, 293 test sample, and 200 validation samples.  Use the code provided below to get started.\n",
    "\n",
    "2) Fit a logistic regression model starting with **Pclass** then adding **Age** and **Sex** if they are significantly non-zero and improve RSS significantly (F-test).\n",
    "\n",
    "3) Use the training and validation set to determine which of these 10 values of L2 weight penalty $\\lambda$ minimizes the negative log-likelihood cost function (same as maximizing the log-likelihood).  Use the following algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Either implement by hand or/and with a Python 3.x package (e.g. sklearn or statsmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wonderful World of ML - Session 4 Discussion: \n",
    "## Linear & Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
