## The Wonderful World of Machine Learning
This is the home for the sessions content for the series on Machine Learning lead by Michael Szczepaniak

### [The first session was June 29, 2017](https://www.meetup.com/Fort-Collins-Data-Science/events/240483138/)
### [Sondra's ML overview, session 1.5, was July 6, 2017](https://www.meetup.com/Fort-Collins-Data-Science/events/240982515/)
### [The second session, Linear Regression - Extreme Interpretability, was July 13, 2017](https://www.meetup.com/Fort-Collins-Data-Science/events/241236268/)
### [The third session, Logistic Regression: Binary Classifier Workhorse, was July 20, 2017](https://www.meetup.com/Fort-Collins-Data-Science/events/241725026/)
### [The fourth session, Linear & Quadratic Discriminant Analysis (LDA & QDA), was July 27, 2017](https://www.meetup.com/Fort-Collins-Data-Science/events/241919131/)
### [The fifth session, Trees: There's Power in Numbers, was August 24, 2017](https://www.meetup.com/Fort-Collins-Data-Science/events/242413786/)

Future session are tentatively schedule for:

- Date to be announced, session 6 - Neural Nets, Part I
- Date to be announced, session 7 - Neural Nets, Part II
- We may do additional Neural Net sessions if there is enough interest.

### Proposed Agenda

My goal for these sessions is for you to leave them with a good intuition for how the basic machine learning algorithms work and hopefully with a good enough start into how you might implement them yourself.

To get the most out of these sessions, I recommend that you install Jupyter notebook and configure an R kernel in addition to the Python kernel that was installed with Jupyter.  I'll be creating notebooks which use both R and Python code.

I'm going to try to work in concepts such as how to train models with boostrap methods like bagging, random forest and boosting as well as how the main cross-validation techniques work, but we may not have enough time to do much with these areas. Let me know your thoughts on how these sessions might be more beneficial to you!